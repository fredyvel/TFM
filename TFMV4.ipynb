{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec74ba1-066e-4773-8739-7745276c12fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.widgets.text(\"min_T\", \"\")\n",
    "dbutils.widgets.text(\"max_T\", \"\")\n",
    "dbutils.widgets.text(\"Dimensions\", \"\")\n",
    "dbutils.widgets.text(\"tasks\", \"\")\n",
    "dbutils.widgets.text(\"Rows\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "647905b2-09b6-4b31-9685-e7c026f27467",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from andi_datasets.datasets_challenge import challenge_theory_dataset\n",
    "from andi_datasets.datasets_theory import datasets_theory \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras as kr\n",
    "from keras import models, layers ,Sequential\n",
    "from keras.layers import Dense,Conv1D,Flatten,BatchNormalization,MaxPooling1D,Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import seaborn as sns\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc51f50-addd-484b-af8e-2c86a2b75b74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "200\n",
      "2\n",
      "1\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "min_t=199\n",
    "max_t=200\n",
    "task=2\n",
    "dim=1\n",
    "row=1000000\n",
    "\n",
    "print(min_t)\n",
    "print(max_t)\n",
    "print(task)\n",
    "print(dim)\n",
    "print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5916c8e-3bfc-42d8-96dd-4f18a67842b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n",
      "Generating dataset for dimension 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.11/site-packages/andi_datasets/models_theory.py:95: RuntimeWarning: overflow encountered in power\n",
      "  dt = (1-np.random.rand(T))**(-1/sigma)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dataset for task(s) 2 and dimension(s) 1.\n"
     ]
    }
   ],
   "source": [
    "X1_val,Y1_val, X2_val, Y2_val,X3_val,Y3_val=challenge_theory_dataset(min_T = 199, max_T = 200,N = 20000,dimensions = 1,tasks = 2,save_dataset = False)\n",
    "\n",
    "X1,Y1, X2, Y2,X3,Y3=challenge_theory_dataset(min_T = 199, max_T = 200,dimensions = 1,tasks = 2,load_dataset = True)\n",
    "AD = datasets_theory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7706d119-1bdf-4efe-97eb-92ac966cb7ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "211d4786-596e-4bb6-866b-8bf1bd45aef0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2[0],Y2[0], test_size=.2, random_state=1)\n",
    "\n",
    "X2_val, X_test_val, Y2_val, y_test_val = train_test_split(X2_val[0],Y2_val[0], test_size=.2, random_state=1)\n",
    "\n",
    "X_train_re = np.array(X_train)\n",
    "y_train_cat = to_categorical(y_train, num_classes=5)\n",
    "X_test_re = np.array(X_test)\n",
    "y_test_cat = to_categorical(y_test, num_classes=5)\n",
    "X_val_re = np.array(X2_val)\n",
    "y_val_cat = to_categorical(Y2_val, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b96a02e6-1490-422c-abc8-636e996745cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X:80000\n",
      "Train Y:80000\n",
      "Test X:20000\n",
      "Test Y:20000\n",
      "Val X:16000\n",
      "Val Y:16000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X:\"+str(len(X_train)))\n",
    "print(\"Train Y:\"+str(len(y_train)))\n",
    "print(\"Test X:\"+str(len(X_test)))\n",
    "print(\"Test Y:\"+str(len(y_test)))\n",
    "print(\"Val X:\"+str(len(X_val_re)))\n",
    "print(\"Val Y:\"+str(len(y_val_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f41fc171-b751-4d50-bc1e-09d064fa19ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Calcular los pesos para cada clase para balancear el entrenamiento\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Creación del modelo secuencial\n",
    "model = Sequential(name=\"Modelo_Convolucional\")\n",
    "\n",
    "# Añadir capa convolucional 1D como capa de entrada\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(199, 1), name='Conv1D_entrada'))\n",
    "\n",
    "# Añadir otra capa convolucional 1D\n",
    "model.add(Conv1D(filters=64, activation='relu', kernel_size=5, name='Conv1D_2'))\n",
    "# Añadir una capa de Max Pooling para reducir la dimensionalidad\n",
    "model.add(MaxPooling1D(pool_size=2, name='MaxPooling1D_1'))\n",
    "# Añadir Dropout para regularización, evitar el sobreajuste\n",
    "model.add(Dropout(0.5, name='Dropout_1'))\n",
    "\n",
    "# Continuar con más capas convolucionales y de pooling\n",
    "model.add(Conv1D(filters=128, activation='relu', kernel_size=3, name='Conv1D_3'))\n",
    "model.add(Conv1D(filters=128, activation='relu', kernel_size=3, name='Conv1D_4'))\n",
    "model.add(MaxPooling1D(pool_size=2, name='MaxPooling1D_2'))\n",
    "model.add(Dropout(0.5, name='Dropout_2'))\n",
    "\n",
    "# Aplanar los datos para poder conectarlos con capas densas\n",
    "model.add(Flatten(name='Flatten'))\n",
    "\n",
    "# Añadir capas densas para clasificación\n",
    "model.add(Dense(128, activation='relu', name='Dense_1'))\n",
    "model.add(Dense(5, activation='softmax', name='Dense_salida'))  # 5 clases\n",
    "\n",
    "# Configurar el optimizador, en este caso Adam con tasa de aprendizaje y norma máxima\n",
    "optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "# Compilar el modelo con función de pérdida y métricas\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Añadir callbacks para el entrenamiento: parada temprana y guardar el mejor modelo\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento y validación, usando los pesos de clase y callbacks definidos\n",
    "\n",
    "history = model.fit(X_train_re, y_train_cat, epochs=100, batch_size=32, validation_data=(X_val_re, y_val_cat), class_weight=class_weight_dict, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31cb348b-c833-48a3-ae56-383b25005908",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "loaded_model = load_model('best_model.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18af9401-7823-4bad-9aeb-c81df5361807",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = loaded_model.predict(X_test_re) \n",
    "\n",
    "print('accuracy: ',accuracy_score(np.array(y_test),np.argmax(y_pred, axis = 1)))\n",
    "print('f1_score ',f1_score(np.array(y_test),np.argmax(y_pred, axis = 1), average='micro'))\n",
    "print(\"Accuracy:\", accuracy_score(np.array(y_test), np.argmax(y_pred, axis = 1)))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(np.array(y_test), np.argmax(y_pred, axis = 1)))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(np.array(y_test), np.argmax(y_pred, axis = 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "103a2990-7b5b-40f0-84a4-b1a5ff1c8cd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1413  668  552   27 1281]\n",
      " [ 181 3691  142    0   12]\n",
      " [  45  296 2502   96 1099]\n",
      " [   1    4   16 3925   33]\n",
      " [ 161    6  840   58 2951]]\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(np.array(y_test), np.argmax(y_pred, axis = 1))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a44ef41e-89b0-4f31-a28f-c0b80b8f24f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 37 29  1 20]\n",
      " [13 69 31  4 15]\n",
      " [10 40 68  1 21]\n",
      " [ 6 12  9 82 16]\n",
      " [20 26 29  6 30]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.array(y_test),np.argmax(y_pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92420ee6-8247-432f-8d2e-192d75a668f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mlflow-experiment\").load()\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb5d6d9d-3bdc-4c1f-beed-48814b3325b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TP': array([1413, 3691, 2502, 3925, 2951]),\n",
       " 'FP': array([ 388,  974, 1550,  181, 2425]),\n",
       " 'FN': array([2528,  335, 1536,   54, 1065]),\n",
       " 'TN': array([15671, 15000, 14412, 15840, 13559]),\n",
       " 'Precision': array([0.78456413, 0.79121115, 0.61747285, 0.95591817, 0.54892113]),\n",
       " 'Recall': array([0.35853844, 0.91679086, 0.61961367, 0.98642875, 0.73481076]),\n",
       " 'Accuracy': 0.8262}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "confusion_matrix=cm\n",
    "# Calcular las métricas de rendimiento\n",
    "# Verdaderos Positivos (diagonal de la matriz)\n",
    "TP = np.diag(confusion_matrix)\n",
    "\n",
    "# Falsos Positivos (suma de las columnas de la matriz - Verdaderos Positivos)\n",
    "FP = np.sum(confusion_matrix, axis=0) - TP\n",
    "\n",
    "# Falsos Negativos (suma de las filas de la matriz - Verdaderos Positivos)\n",
    "FN = np.sum(confusion_matrix, axis=1) - TP\n",
    "\n",
    "# Verdaderos Negativos (suma total de la matriz - (FP + FN + TP))\n",
    "TN = np.sum(confusion_matrix) - (FP + FN + TP)\n",
    "\n",
    "# Precisión (Precision)\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "# Sensibilidad (Recall)\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "# Exactitud (Accuracy)\n",
    "accuracy = np.sum(TP) / np.sum(confusion_matrix)\n",
    "\n",
    "performance_metrics = {\n",
    "    \"TP\": TP,\n",
    "    \"FP\": FP,\n",
    "    \"FN\": FN,\n",
    "    \"TN\": TN,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"Accuracy\": accuracy\n",
    "}\n",
    "\n",
    "performance_metrics\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 715995793716724,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "TFM_Presentado",
   "widgets": {
    "Dimensions": {
     "currentValue": "1",
     "nuid": "7a4013f0-0f6d-453d-b552-27a687ff5946",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "Dimensions",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "Rows": {
     "currentValue": "20000",
     "nuid": "ebe578c5-05f2-4037-b198-9153878c49fa",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "Rows",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "max_T": {
     "currentValue": "200",
     "nuid": "d3df071d-7864-4cf7-a7a6-e9910627d824",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "max_T",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "min_T": {
     "currentValue": "199",
     "nuid": "7fdbedc0-9ec1-4604-b180-b2866f0d3582",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "min_T",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "tasks": {
     "currentValue": "2",
     "nuid": "ab81f55b-ea5d-4b9a-836e-3c18ef3420c6",
     "typedWidgetInfo": null,
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "tasks",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python (AmbienteTFM)",
   "language": "python",
   "name": "kerneltfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
